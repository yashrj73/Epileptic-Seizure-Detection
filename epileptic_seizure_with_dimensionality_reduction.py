# -*- coding: utf-8 -*-
"""Epileptic Seizure with Dimensionality Reduction

Automatically generated by Colaboratory.

Original file and results are located at
    https://colab.research.google.com/drive/1eF6wJcrZe7O88vwBTgt0TZBboqFxDFbS
"""

import pandas as pd 
import matplotlib.pyplot as plt

!pip install -U -q PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# 2. Load a file by ID and create local file.
downloaded = drive.CreateFile({'id':'1bob-_JM3_WHMoxYZxypUTsX---u5Z2YN'}) # replace fileid with Id of file you want to access
downloaded.GetContentFile('export.csv') # now you can use export.csv

dataset=pd.read_csv('export.csv')
print(dataset.shape)
#print(dataset)

fig=plt.figure()
ax = fig.add_subplot(1,1,1)
ax.hist(dataset['y'])

import numpy as np

dataset.shape

target=dataset['y']
X=['X59','X84','X113','X83','X115','X114','X58','X82','X85','X53','X52','X51','X142','X76','X87','X143','X75','X122','X116','X79','X50','X62','X60','X117','X80','X155','X145','X146','X49','X22','X133','X144','X154','X61','X139','X141','X103','X140','X10','X23','X118','X86','X74','X102','X24','X21','X135','X101','X77','X81','X112','X99','X138','X134','X123','X48','X11','X12','X156','X54', 'X136','X148','X88','X119','X147','X25','X153','X13','X120','X100','X9','X78','X63','X169','X57','X132','X167','X64','X121','X20','X137','X124','X65','X8','X176']
#variable = dataset[X]
#lda = LDA(n_components=2)
#sne = TSNE(n_components=2)

from sklearn.preprocessing import StandardScaler
#features = ['X1','X52',X53','X54','X59','X60','X76','X77','X83','X84','X85','X86','X88','X114','X115','X116','X117','X123','X143','X144']
# Separating out the features
x = dataset.loc[:, X].values
# Separating out the target
#print(x)
y = dataset.loc[:,['y']].values
# Standardizing the features
x = StandardScaler().fit_transform(x)
#print(x)
print(x.shape)

i=0
for v in np.nditer(y):
  v = v - 1
  y[i] = v
  i = i + 1
print(y)

#Data Preprocessing
np.random.seed(42)

x=pd.DataFrame(x)
y=pd.DataFrame(y)
#print(x)
y.columns = [85]
#print(y)

import pandas as pd
z = [x, y]
dataset = pd.concat(z, axis=1)
print(dataset)

from sklearn.model_selection import train_test_split

from keras.utils import to_categorical
target = dataset[85]
#print(target)
one_hot = to_categorical(target, num_classes = 5)
#print(one_hot)
print(dataset.shape)

TrainSet, TestSet = train_test_split(dataset, test_size=0.2, random_state=42)

xTrain = TrainSet.iloc[:, :-1]
yTrain = TrainSet.iloc[:,-1]
yTrain = to_categorical(yTrain, num_classes = 5)
print(xTrain.shape)
print(yTrain.shape)

xTest = TestSet.iloc[:, :-1]
yTest = TestSet.iloc[:,-1]
yTest = to_categorical(yTest, num_classes = 5)
print(xTest.shape)
print(yTest.shape)

print(dataset.shape)
print(xTrain.shape, yTrain.shape, xTest.shape, yTest.shape, )

from keras.models import Sequential
from keras.layers import Dense
#from keras.layers import LSTM
from keras.layers import Dropout
from keras import optimizers

#Building time series model
model = Sequential()

#First layer
model.add(Dense(output_dim = 70, activation = 'relu', input_dim = 85))
model.add(Dropout(0.2))

#2nd layer
model.add(Dense(output_dim = 70, activation = 'relu'))
model.add(Dropout(0.2))

#3rd layer
#model.add(Dense(output_dim = 13, activation = 'relu'))

#4th layer
#model.add(Dense(output_dim = 30, activation = 'relu'))

#5th layer
model.add(Dense(5, activation = 'softmax'))

#Compile
#RMSprop = optimizers.RMSprop(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
model.compile(optimizer = 'RMSprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])

#Summary
print(model.summary())

history = model.fit(xTrain, yTrain, epochs=200, validation_split=0.33, batch_size=20)

target = model.predict(xTest)

score = model.evaluate(xTest, yTest, batch_size = 30)
print(model.metrics_names)
print(score)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()



plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

